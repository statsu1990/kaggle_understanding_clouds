from script.my_util import *
from keras.models import load_model, Model
import keras
from tta_wrapper import tta_segmentation
import numpy as np

from model import base_unet, myunet, mylosses, mydeeplab, myoptimizer
from script import mygenerator as mygen
import os
import datetime
import cv2
import matplotlib.pyplot as plt


def make_dir(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)
    return

def set_seed(seed):
    seed_everything(seed)
    return

def make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2):
    # Load data
    train = pd.read_csv('../input/train.csv')
    submission = pd.read_csv('../input/sample_submission.csv')

    # Preprocecss data
    train['image'] = train['Image_Label'].apply(lambda x: x.split('_')[0])
    train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])
    submission['image'] = submission['Image_Label'].apply(lambda x: x.split('_')[0])
    test = pd.DataFrame(submission['image'].unique(), columns=['image'])

    # Create one column for each mask
    train_df = pd.pivot_table(train, index=['image'], values=['EncodedPixels'], columns=['label'], aggfunc=np.min).reset_index()
    train_df.columns = ['image', 'Fish_mask', 'Flower_mask', 'Gravel_mask', 'Sugar_mask']

    # Train and validation split
    X_train, X_val = train_test_split(train_df, test_size=test_size, random_state=split_seed)
    X_train['set'] = 'train'
    X_val['set'] = 'validation'
    test['set'] = 'test'

    return train, submission, test, train_df, X_train, X_val


def pipeline19110701():
    DEBUG = False
    SHOW_IMG = True
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110701_deeplab_test')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 16 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.99),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = load_model(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110801():
    #AdamAccumulate動かない。。
    DEBUG = True
    SHOW_IMG = True
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110801_deeplab_test')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 16 # 32
    EPOCHS = 60 if not DEBUG else 1
    LEARNING_RATE = 0.002 #3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.99),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    #OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    #OPTIMIZER = myoptimizer.AdamAccumulate(lr=LEARNING_RATE, accum_iters=8)
    OPTIMIZER = myoptimizer.AdamAccumulate(lr=LEARNING_RATE, accum_iters=8)
    #LOSS_FUNC = mylosses.bce_ls01_dice_loss
    LOSS_FUNC = mylosses.bce_dice_loss
    model = mydeeplab.mydeeplab_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = load_model(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110802():
    DEBUG = False
    SHOW_IMG = True
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110802_deeplab_v1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 16 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.99),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = load_model(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110803():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110803_masked_deeplab_v1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 16 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 5 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.99),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.mask_bce_ls01_dice_loss
    #model = mydeeplab.mydeeplab_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)
    #model = mydeeplab.mydeeplab_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)
    model = mydeeplab.mydeeplab_mask_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        #model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = load_model(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)[...,:4]

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)[...,:4]

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110803test():
    DEBUG = True
    SHOW_IMG = False
    TRAINING = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110803_masked_deeplab_v1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 16 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 5 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.99),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.mask_bce_ls01_dice_loss
    #model = mydeeplab.mydeeplab_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)
    #model = mydeeplab.mydeeplab_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)
    model = mydeeplab.mydeeplab_mask_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        #model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = model.load_weights(model_path)
        #model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)







    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)[...,:4]

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)[...,:4]

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110804():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110804_deeplab_v2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.99),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = load_model(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110805():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110805_deeplab_v3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = load_model(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110805():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110805_deeplab_v3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipeline19110805test():
    DEBUG = False
    SHOW_IMG = True
    TRAINING = False
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110805_deeplab_v3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.4, .4, .4, .25]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.6, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])

                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110806():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110806_deeplab_v4')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.99),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = load_model(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110807():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110807_deeplab_v3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model = load_model(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipeline19110901():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110901_deeplab_v6')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19110901test():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110901_deeplab_v6test')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join('result', '19110901_deeplab_v6', 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19110902():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110902_deeplab_v7')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    # Apply model to test set
    model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
    # test data
    test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

    test_df = []
    for i in range(0, test.shape[0], 300):
        batch_idx = list(range(i, min(test.shape[0], i + 300)))
        batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
        test_generator = mygen.DataGenerator2(
                          images=test_imgs,
                          imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                          masks=None,
                          imageName_to_maskIdx_dict=None,
                          dataframe=batch_set,
                          batch_size=1, 
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          seed=SEED,
                          mode='predict',
                          shuffle=False)

        preds = model.predict_generator(test_generator)

        for index, b in enumerate(batch_idx):
            filename = test['image'].iloc[b]
            image_df = submission[submission['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels'] = pred_rles

            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_post'] = pred_rles_post
            ###
        
            test_df.append(image_df)

    sub_df = pd.concat(test_df)

    # Regular submission
    submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
    submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
    print(submission_df.head())

    # Submission with post processing
    submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
    submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
    submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
    print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        # 
        # Without post-process
        # Choose 5 samples at random
        images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

        # ## With post-process
        inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
# standard
def pipeline19110902test():
    DEBUG = False
    SHOW_IMG = True
    TRAINING = False
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110902_deeplab_v7')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19110903():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110903_deeplab_v8')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 200
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v4(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19110904():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19110904_deeplab_v9')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 200
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 6 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v5(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipeline19111001():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111001_deeplab_v10')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    MIXHALF_P = 0.5
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        #for i in range(10):
        #    plt.imshow(augmentation(image=train_imgs[i])['image'])
        #    plt.show()
        pass

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED,
                      mixhalf_p=MIXHALF_P,
                      )
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    if DEBUG:
        #a = (train_generator[0][0]+127.5)*127.5
        #a = a.astype('uint8')
        #for i in range(10):
        #    plt.imshow(a[i])
        #    plt.show()
        pass


    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111002():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111002_deeplab_v10_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    MIXHALF_P = 0.6
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        #for i in range(10):
        #    plt.imshow(augmentation(image=train_imgs[i])['image'])
        #    plt.show()
        pass

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED,
                      mixhalf_p=MIXHALF_P,
                      )
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    if DEBUG:
        #a = (train_generator[0][0]+127.5)*127.5
        #a = a.astype('uint8')
        #for i in range(10):
        #    plt.imshow(a[i])
        #    plt.show()
        pass


    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111003():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111003_deeplab_v10_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    MIXHALF_P = 1.0
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        #for i in range(10):
        #    plt.imshow(augmentation(image=train_imgs[i])['image'])
        #    plt.show()
        pass

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED,
                      mixhalf_p=MIXHALF_P,
                      )
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    if DEBUG:
        #a = (train_generator[0][0]+127.5)*127.5
        #a = a.astype('uint8')
        #for i in range(10):
        #    plt.imshow(a[i])
        #    plt.show()
        pass


    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111004():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111004_mask_deeplab_v2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        #for i in range(10):
        #    plt.imshow(augmentation(image=train_imgs[i])['image'])
        #    plt.show()
        pass

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.mask_bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_mask_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        #model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))


    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.4, .4, .4, .25]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # Model evaluation
    train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    print(train_metrics)
    train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    print(validation_metrics)
    validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))




    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)[...,:N_CLASSES]

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111005():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111005_deeplab_v11')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = 30
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    # print(train_metrics)
    # train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    # validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    # print(validation_metrics)
    # validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))

    thresholds_list = [
        [.2, .2, .2, .05],
        [.3, .3, .3, .15],
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        #train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        #print(train_metrics)
        #train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        #validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))



    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111006():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111006_deeplab_v11_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = 50
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    # print(train_metrics)
    # train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    # validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    # print(validation_metrics)
    # validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))

    thresholds_list = [
        [.2, .2, .2, .05],
        [.3, .3, .3, .15],
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        #train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        #print(train_metrics)
        #train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        #validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))



    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111007():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111007_deeplab_v11_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = 10
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    # print(train_metrics)
    # train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    # validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    # print(validation_metrics)
    # validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))

    thresholds_list = [
        [.2, .2, .2, .05],
        [.3, .3, .3, .15],
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        #train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        #print(train_metrics)
        #train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        #validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))



    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111101():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111101_deeplab_l2norm_v1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None

    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    L2_NORM_SCALE = 10
    model = mydeeplab.mydeeplab_l2norm_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, scale=L2_NORM_SCALE)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    # print(train_metrics)
    # train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    # validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    # print(validation_metrics)
    # validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))

    thresholds_list = [
        [.2, .2, .2, .05],
        [.3, .3, .3, .15],
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        #train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        #print(train_metrics)
        #train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        #validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))



    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111102():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111102_deeplab_l2norm_v1_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None

    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    L2_NORM_SCALE = 30
    model = mydeeplab.mydeeplab_l2norm_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, scale=L2_NORM_SCALE)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    # print(train_metrics)
    # train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    # validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    # print(validation_metrics)
    # validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))

    thresholds_list = [
        [.2, .2, .2, .05],
        [.3, .3, .3, .15],
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        #train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        #print(train_metrics)
        #train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        #validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))



    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111103():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111103_deeplab_l2norm_v1_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None

    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    L2_NORM_SCALE = 1
    model = mydeeplab.mydeeplab_l2norm_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, scale=L2_NORM_SCALE)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    # print(train_metrics)
    # train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
    # validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    # print(validation_metrics)
    # validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))

    thresholds_list = [
        [.2, .2, .2, .05],
        [.3, .3, .3, .15],
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        #train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        #print(train_metrics)
        #train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics.csv'))
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        #validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics.csv'))



    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111103test():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = False
    EVAL_TRA =False
    EVAL_VAL =False
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111103_deeplab_l2norm_v1_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None

    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    L2_NORM_SCALE = 1
    model = mydeeplab.mydeeplab_l2norm_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, scale=L2_NORM_SCALE)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    if EVAL_TRA:
        train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        print(train_metrics)
        train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    if EVAL_VAL:
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .05],
        [.3, .3, .3, .15],
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111104():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =True
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111104_deeplab_v12')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    if DEBUG:
        for i in range(10):
            plt.imshow(augmentation(image=train_imgs[i])['image'])
            plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.lovasz_hinge_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]
    
    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    
    # Model evaluation
    if EVAL_TRA:
        train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        print(train_metrics)
        train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    if EVAL_VAL:
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .05],
        [.3, .3, .3, .15],
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111108():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111108_deeplab_v13')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    smooth_overlap_mask_base = 0.7
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        train_generator_fine = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=None,
                      preproc_before_aug=preproc_before_aug,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      seed=SEED)
        history = model.fit_generator(generator=train_generator_fine,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=5,
                                      verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]
    
    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    
    # Model evaluation
    if EVAL_TRA:
        train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        print(train_metrics)
        train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    if EVAL_VAL:
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111201():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =True
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '191112_featvec_deeplab_v1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 10 if not DEBUG else 1
    FINELEARN_EPOCHS = 0
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    model = mydeeplab.mydeeplab_featvec_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, downsize_rate=2/3)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]
    
    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    
    # Model evaluation
    if EVAL_TRA:
        train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        print(train_metrics)
        train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    if EVAL_VAL:
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))


    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline191112standard():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111200_deeplab_vxx')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]
    
    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    
    # Model evaluation
    if EVAL_TRA:
        train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        print(train_metrics)
        train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    if EVAL_VAL:
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline191112standard2():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111200_deeplab_vxx')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    model = mydeeplab.mydeeplab_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .6, .6, .45]
    best_masks = [25000, 20000, 22500, 15000]
    
    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    
    # Model evaluation
    if EVAL_TRA:
        train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
        print(train_metrics)
        train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    if EVAL_VAL:
        validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
        print(validation_metrics)
        validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.4, .4, .4, .25],
        [.5, .5, .5, .35],
        [.6, .6, .6, .45],
        [.7, .7, .7, .55],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .35]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return




def pipeline19111202():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111202_featvec_deeplab_v2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 50 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    model = mydeeplab.mydeeplab_featvec_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, downsize_rate=2/3)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.45, .45, .45, .45],
        [.5, .5, .5, .5],
        [.55, .55, .55, .55],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        [.8, .8, .8, .8],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.5, .5, .5, .5]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111203():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111203_featvec_deeplab_v3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 3
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, downsize_rate=2/3)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.4, .4, .4, .4]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111204():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111204_featvec_deeplab_v4')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 3
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    N_VEC = 4
    model = mydeeplab.mydeeplab_featvec_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, downsize_rate=2/3)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.4, .4, .4, .4]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111205():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111205_featvec_deeplab_v4_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 3
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    N_VEC = 8
    model = mydeeplab.mydeeplab_featvec_v3(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, downsize_rate=2/3)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.4, .4, .4, .4]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111206():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111206_featvec_deeplab_v5')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 3
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    N_VEC = 4
    N_LAST_HIDDEN = N_VEC * 2
    model = mydeeplab.mydeeplab_featvec_v4(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, n_last_hidden=N_LAST_HIDDEN, downsize_rate=2/3)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.4, .4, .4, .4]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
# !
def pipeline19111207():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111207_featvec_deeplab_v5_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 3
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    N_VEC = 8
    N_LAST_HIDDEN = N_VEC * 2
    model = mydeeplab.mydeeplab_featvec_v4(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, n_last_hidden=N_LAST_HIDDEN, downsize_rate=2/3)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.4, .4, .4, .4]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111208():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111208_featvec_deeplab_v6')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 3
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    N_VEC = 8
    N_LAST_HIDDEN = N_VEC * 2
    model = mydeeplab.mydeeplab_featvec_v4_1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, n_last_hidden=N_LAST_HIDDEN, downsize_rate=2/3)

    # training
    if TRAINING:
        checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        callback_list = [checkpoint, rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # # Threshold and mask size tunning
    # #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.4, .4, .4, .4]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111301():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111301_featvec_deeplab_v2_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    model = mydeeplab.mydeeplab_featvec_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111302():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111302_featvec_deeplab_v2_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    N_VEC = 8
    model = mydeeplab.mydeeplab_featvec_v3_1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111303():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111303_featvec_deeplab_v5_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.bce_ls01_dice_loss
    N_VEC = 8
    N_LAST_HIDDEN = N_VEC * 2
    #model = mydeeplab.mydeeplab_featvec_v4(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, n_last_hidden=N_LAST_HIDDEN, downsize_rate=2/3)
    model = mydeeplab.mydeeplab_featvec_v4_2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, n_last_hidden=N_LAST_HIDDEN, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipeline19111304():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111304_featvec_deeplab_v3_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.1
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, regu_coef=REGU_COEF, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111305():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111305_featvec_deeplab_v3_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, regu_coef=REGU_COEF, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111306():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111306_featvec_deeplab_v3_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = 1e-6
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, regu_coef=REGU_COEF, act_regu_coef=ACT_REGU_COEF, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111307():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111307_featvec_deeplab_v3_4')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = 1e-8
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, regu_coef=REGU_COEF, act_regu_coef=ACT_REGU_COEF, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111308():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111308_featvec_deeplab_v2_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    model = mydeeplab.mydeeplab_featvec_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, regu_coef=REGU_COEF, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        metric_list = [dice_coef, sm.metrics.iou_score]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        model.save_weights(model_path)
    # load
    else:
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111401():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111401_featvec_deeplab_v2_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v1(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111402():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111402_featvec_deeplab_v3_5_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111402test():
    DEBUG = False
    SHOW_IMG = True
    TRAINING = False
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111402_featvec_deeplab_v3_5_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        #[.2, .2, .2, .2],
        #[.3, .3, .3, .3],
        [.39, .39, .39, .39],
        #[.4, .4, .4, .4],
        #[.5, .5, .5, .5],
        #[.6, .6, .6, .6],
        #[.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.39, .39, .39, .39]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline191114standard():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '191114xx_featvec_deeplab_v3_5_x')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipeline19111403():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111403_featvec_deeplab_v3_5_2_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = 0.5
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111404():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111404_featvec_deeplab_v3_5_2_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = 0.7
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111405():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111405_featvec_deeplab_v3_5_3_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = 10
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111406():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111406_featvec_deeplab_v3_5_3_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = 50
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111407():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111407_featvec_deeplab_v3_5_4_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin005_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111408():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111408_featvec_deeplab_v3_5_4_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin00_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111409():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111409_featvec_deeplab_v3_5_5_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 0
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111410():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111410_featvec_deeplab_v3_5_6_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = 0.5
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipeline19111501():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111501_featvec_deeplab_v7')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2_2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111502():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111502_featvec_deeplab_v7_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    SCALING = True
    model = mydeeplab.mydeeplab_featvec_v2_2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           scaling=SCALING, downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=5,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111503():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111503_featvec_deeplab_v3_7_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    START_EPOCH = 5 if not DEBUG else 1
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5 if not DEBUG else 1
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE


        # --------------
        if START_EPOCH > 0:
            START_OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)

            for ly in model.layers[:-3]:
                #if not ly.name.startswith('batch_normalization'):
                if type(ly) != type(keras.layers.BatchNormalization()):
                    ly.trainable = False

            model.compile(optimizer=START_OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
            model.summary()

            history = model.fit_generator(generator=train_generator,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=START_EPOCH,
                                          verbose=1).history

            for ly in model.layers:
                ly.trainable = True

        # --------------

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipeline19111504():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111504_featvec_deeplab_v3_5_1_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        #rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        rlrop = ReduceLROnPlateau(monitor='val_dice_coef', mode='max', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111505():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111505_featvec_deeplab_v3_5_7')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111506():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111506_featvec_deeplab_v3_5_1_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 100 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 7 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = 0.5
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin005_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'leakyrelu'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        #rlrop = ReduceLROnPlateau(monitor='val_dice_coef', mode='max', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), rotation=180, merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

# size = 1/1
def pipeline19111610():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111610_featvec_deeplab_v3_10_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 7 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=1/1)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        #rlrop = ReduceLROnPlateau(monitor='val_dice_coef', mode='max', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), rotation=180, merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111701():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111701_featvec_deeplab_v3_17_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.my_l_n_margin01_dice_loss_wrapper(c0=2.0, c1=1)
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111702():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111702_featvec_deeplab_v3_17_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.my_l_n_margin01_dice_loss_wrapper(c0=2.0, c1=0.5)
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111703():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111703_featvec_deeplab_v3_17_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.my_l_n_margin01_dice_loss_wrapper(c0=3.0, c1=0.5)
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111704():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111704_featvec_deeplab_v3_17_4')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.my_l_n_margin01_dice_loss_wrapper(c0=3.0, c1=0.3)
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111705():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111704_featvec_deeplab_v3_17_5')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.cce_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipeline19111710():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111710_featvec_deeplab_v3_17_10_1')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19111501, test_size=0.1)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input19111501/train_images/'
    validation_images_dest_path = '../proc_input19111501/validation_images/'
    test_images_dest_path = '../proc_input19111501/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.cce_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111711():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111711_featvec_deeplab_v3_17_10_2')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19111502, test_size=0.01)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input19111502/train_images/'
    validation_images_dest_path = '../proc_input19111502/validation_images/'
    test_images_dest_path = '../proc_input19111502/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.cce_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

# !
def pipeline19111712():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111712_featvec_deeplab_v3_17_10_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19111501, test_size=0.1)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input19111501/train_images/'
    validation_images_dest_path = '../proc_input19111501/validation_images/'
    test_images_dest_path = '../proc_input19111501/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipeline19111713():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111713_featvec_deeplab_v3_17_10_3')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19111502, test_size=0.01)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input19111502/train_images/'
    validation_images_dest_path = '../proc_input19111502/validation_images/'
    test_images_dest_path = '../proc_input19111502/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return
def pipeline19111714():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = True
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = False

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '19111714_featvec_deeplab_v3_17_10_4')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19111502, test_size=0.01)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input19111502/train_images/'
    validation_images_dest_path = '../proc_input19111502/validation_images/'
    test_images_dest_path = '../proc_input19111502/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 7 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True
    model = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=1/1)

    # training
    if TRAINING:
        #checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)
        rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)
        csvlogger = CSVLogger(os.path.join(RESULT_DIR, 'learning_log.csv'))

        #metric_list = [dice_coef, sm.metrics.iou_score]
        metric_list = [dice_coef]
        #callback_list = [checkpoint, rlrop, csvlogger]
        callback_list = [rlrop, csvlogger]

        model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=metric_list)
        model.summary()

        STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE
        STEP_SIZE_VALID = len(X_val)//BATCH_SIZE

        history = model.fit_generator(generator=train_generator,
                                      steps_per_epoch=STEP_SIZE_TRAIN,
                                      validation_data=valid_generator,
                                      validation_steps=STEP_SIZE_VALID,
                                      callbacks=callback_list,
                                      epochs=EPOCHS,
                                      verbose=1).history

        # fine
        if FINELEARN_EPOCHS > 0:
            train_generator_fine = mygen.DataGenerator2(
                          images=train_imgs,
                          imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                          masks=train_masks,
                          imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                          dataframe=X_train,
                          batch_size=BATCH_SIZE,
                          target_size=(HEIGHT, WIDTH),
                          n_channels=CHANNELS,
                          n_classes=N_CLASSES,
                          preprocessing=preprocessing,
                          augmentation=None,
                          preproc_before_aug=preproc_before_aug,
                          mask_avefilter_kernel=mask_avefilter_kernel,
                          smooth_overlap_mask_base=smooth_overlap_mask_base,
                          seed=SEED)
            history = model.fit_generator(generator=train_generator_fine,
                                          steps_per_epoch=STEP_SIZE_TRAIN,
                                          validation_data=valid_generator,
                                          validation_steps=STEP_SIZE_VALID,
                                          callbacks=callback_list,
                                          epochs=FINELEARN_EPOCHS,
                                          verbose=1).history

        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()

        model.save_weights(model_path)
    # load
    else:
        if USE_RELU_WRAPPER:
            print('using relu wrapper')
            model = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model)
            model.summary()
        print('load weights')
        model.load_weights(model_path)
        model.summary()


    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipline_test_19111801():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = False
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '191118_test_01')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True

    #--------------------------------------
    model1 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model1 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model1)
        model1.summary()
    print('load weights')

    model_path = os.path.join('result', '19111601_featvec_deeplab_v3_5_16_1', 'deeplav.h5')
    model1.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model2 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model2 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model2)
        model2.summary()
    print('load weights')

    model_path = os.path.join('result', '19111713_featvec_deeplab_v3_17_10_3', 'deeplav.h5')
    model2.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    _inp = model1.input
    _oup1 = model1(_inp)
    _oup2 = model2(_inp)
    _oup = keras.layers.Average()([_oup1, _oup2])
    model = Model(input=_inp, output=_oup)
    #--------------------------------------

    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.1, .1, .1, .1],
        [.2, .2, .2, .2],
        [.3, .3, .3, .3],
        [.4, .4, .4, .4],
        [.5, .5, .5, .5],
        [.6, .6, .6, .6],
        [.7, .7, .7, .7],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean', rotation=180)
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

# !
def pipline_test_19111802():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = False
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '191118_test_02')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True

    #--------------------------------------
    model1 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model1 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model1)
        model1.summary()
    print('load weights')

    model_path = os.path.join('result', '19111601_featvec_deeplab_v3_5_16_1', 'deeplav.h5')
    model1.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model2 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model2 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model2)
        model2.summary()
    print('load weights')

    model_path = os.path.join('result', '19111713_featvec_deeplab_v3_17_10_3', 'deeplav.h5')
    model2.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model3 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model3 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model3)
        model3.summary()
    print('load weights')

    model_path = os.path.join('result', '19111712_featvec_deeplab_v3_17_10_3', 'deeplav.h5')
    model3.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    _inp = model1.input
    _oup1 = model1(_inp)
    _oup2 = model2(_inp)
    _oup3 = model3(_inp)
    _oup = keras.layers.Average()([_oup1, _oup2, _oup3])
    model = Model(input=_inp, output=_oup)
    #--------------------------------------

    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean', rotation=180)
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipline_test_19111803():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = False
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '191118_test_03')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True

    #--------------------------------------
    model1 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model1 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model1)
        model1.summary()
    print('load weights')

    model_path = os.path.join('result', '19111714_featvec_deeplab_v3_17_10_4', 'deeplav.h5')
    model1.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model2 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model2 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model2)
        model2.summary()
    print('load weights')

    model_path = os.path.join('result', '19111713_featvec_deeplab_v3_17_10_3', 'deeplav.h5')
    model2.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    _inp = model1.input
    _oup1 = model1(_inp)
    _oup2 = model2(_inp)
    _oup = keras.layers.Average()([_oup1, _oup2])
    model = Model(input=_inp, output=_oup)
    #--------------------------------------

    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean', rotation=180)
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return


def pipline_test_19111804():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = False
    EVAL_TRA =False
    EVAL_VAL =True
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '191118_test_04')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True

    #--------------------------------------
    model1 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model1 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model1)
        model1.summary()
    print('load weights')

    model_path = os.path.join('result', '19111714_featvec_deeplab_v3_17_10_4', 'deeplav.h5')
    model1.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model2 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model2 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model2)
        model2.summary()
    print('load weights')

    model_path = os.path.join('result', '19111713_featvec_deeplab_v3_17_10_3', 'deeplav.h5')
    model2.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model3 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model3 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model3)
        model3.summary()
    print('load weights')

    model_path = os.path.join('result', '19111712_featvec_deeplab_v3_17_10_3', 'deeplav.h5')
    model3.load_weights(model_path)
    #--------------------------------------
    ##--------------------------------------
    #model4 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
    #                                       regu_coef=REGU_COEF, 
    #                                       oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
    #                                       downsize_rate=1/1)
    ## load
    #if USE_RELU_WRAPPER:
    #    print('using relu wrapper')
    #    model4 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model4)
    #    model4.summary()
    #print('load weights')
    #
    #model_path = os.path.join('result', '19111610_featvec_deeplab_v3_10_1', 'deeplav.h5')
    #model4.load_weights(model_path)
    #--------------------------------------
    ##--------------------------------------
    #model5 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
    #                                       regu_coef=REGU_COEF, 
    #                                       oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
    #                                       downsize_rate=2/3)
    ## load
    #if USE_RELU_WRAPPER:
    #    print('using relu wrapper')
    #    model5 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model1)
    #    model5.summary()
    #print('load weights')
    #
    #model_path = os.path.join('result', '19111601_featvec_deeplab_v3_5_16_1', 'deeplav.h5')
    #model5.load_weights(model_path)
    ##--------------------------------------
    #--------------------------------------
    N_VEC = 8
    N_LAST_HIDDEN = N_VEC * 2
    model4 = mydeeplab.mydeeplab_featvec_v4(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, n_last_hidden=N_LAST_HIDDEN, downsize_rate=2/3)
    model_path = os.path.join('result', '19111207_featvec_deeplab_v5_1', 'deeplav.h5')
    model4.load_weights(model_path)
    #--------------------------------------

    #--------------------------------------
    _inp = model1.input
    _oup1 = model1(_inp)
    _oup2 = model2(_inp)
    _oup3 = model3(_inp)
    _oup4 = model4(_inp)
    #_oup5 = model5(_inp)
    #_oup6 = model6(_inp)
    #_oup = keras.layers.Average()([_oup1, _oup2, _oup3, _oup4, _oup5, _oup6])
    #_oup = keras.layers.Average()([_oup1, _oup2, _oup3, _oup4, _oup5])
    _oup = keras.layers.Average()([_oup1, _oup2, _oup3, _oup4])
    model = Model(input=_inp, output=_oup)
    #--------------------------------------

    # #####################
    # evaluation
    # #####################

    # Threshold and mask size tunning
    #  - Here we could use some kind of parameter search, but to simplify I'm using default values
    # class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    # best_tresholds = [.5, .6, .6, .45]
    # best_masks = [25000, 20000, 22500, 15000]
    # 
    # for index, name in enumerate(class_names):
    #     print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))
    # 
    # # Model evaluation
    # if EVAL_TRA:
    #     train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
    #     print(train_metrics)
    #     train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
    # if EVAL_VAL:
    #     validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
    #     print(validation_metrics)
    #     validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    thresholds_list = [
        [.3, .3, .3, .3],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean', rotation=180)
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return

def pipline_test_19111805():
    DEBUG = False
    SHOW_IMG = False
    TRAINING = False
    EVAL_TRA =False
    EVAL_VAL =False
    TEST = True

    # #####################
    # preprare
    # #####################
    # result dir
    RESULT_DIR = os.path.join('result', '191118_test_05')
    make_dir(RESULT_DIR)

    # seed
    SEED = None
    set_seed(SEED)

    # Load data, Preprocecss data, Create one column for each mask, Train and validation split
    train, submission, test, train_df, X_train, X_val = make_train_submission_test_train_df_X_train_X_val(split_seed=19110303, test_size=0.2)

    if DEBUG:
        num_data_debug = 40
        X_train, X_val, test = X_train[:num_data_debug], X_val[:num_data_debug], test[:num_data_debug]

    # Pre-process data
    train_images_dest_path = '../proc_input/train_images/'
    validation_images_dest_path = '../proc_input/validation_images/'
    test_images_dest_path = '../proc_input/test_images/'

    # image shape
    HEIGHT, WIDTH, CHANNELS = 384, 480, 3

    # read image, calc mask
    train_imgs, train_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), train_images_dest_path, X_train)
    valid_imgs, valid_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), validation_images_dest_path, X_val)
    train_masks, train_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_train)
    valid_masks, valid_imageName_to_maskIdx_dict = calc_mask((HEIGHT, WIDTH, CHANNELS), train, X_val)

    # ###################
    # training model
    # ###################
    # Model parameters
    N_CLASSES = 4
    BATCH_SIZE = 10 # 32
    EPOCHS = 30 if not DEBUG else 1
    FINELEARN_EPOCHS = 5
    LEARNING_RATE = 3e-4
    ES_PATIENCE = 5
    RLROP_PATIENCE = 3 #3
    DECAY_DROP = 0.5
    model_path = os.path.join(RESULT_DIR, 'deeplav.h5')
    #
    mask_avefilter_kernel = None
    smooth_overlap_mask_base = None
    GAMMA_COR = None
    def preprocessing(_img):
        if GAMMA_COR is not None:
            _img = gamma_correction(_img, gamma=GAMMA_COR)
        _img = (_img - 127.5) / 127.5
        return _img
    #
    MIXHALF_P = None
    augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),
                                 albu.VerticalFlip(p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5),
                                 #albu.ShiftScaleRotate(rotate_limit=20, shift_limit=0.1, scale_limit=0.05, p=0.5),
                                 albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, scale_limit=0.1, 
                                                       border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0, p=0.5),
                                 albu.RandomBrightness(limit=0.2, p=0.99),
                                 #albu.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.5),
                                ])
    preproc_before_aug = False
    #if DEBUG:
    #    for i in range(10):
    #        plt.imshow(augmentation(image=train_imgs[i])['image'])
    #        plt.show()

    # Data generator
    train_generator = mygen.DataGenerator2(
                      images=train_imgs,
                      imageName_to_imageIdx_dict=train_imageName_to_imageIdx_dict,
                      masks=train_masks,
                      imageName_to_maskIdx_dict=train_imageName_to_maskIdx_dict,
                      dataframe=X_train,
                      batch_size=BATCH_SIZE,
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      augmentation=augmentation,
                      preproc_before_aug=preproc_before_aug,
                      mask_avefilter_kernel=mask_avefilter_kernel,
                      smooth_overlap_mask_base=smooth_overlap_mask_base,
                      mixhalf_p=MIXHALF_P,
                      seed=SEED)
    valid_generator = mygen.DataGenerator2(
                      images=valid_imgs,
                      imageName_to_imageIdx_dict=valid_imageName_to_imageIdx_dict,
                      masks=valid_masks,
                      imageName_to_maskIdx_dict=valid_imageName_to_maskIdx_dict,
                      dataframe=X_val,
                      batch_size=BATCH_SIZE, 
                      target_size=(HEIGHT, WIDTH),
                      n_channels=CHANNELS,
                      n_classes=N_CLASSES,
                      preprocessing=preprocessing,
                      seed=SEED)

    #if DEBUG:
    #    a = (train_generator[0][0]+127.5)*127.5
    #    a = a.astype('uint8')
    #    for i in range(10):
    #        plt.imshow(a[i])
    #        plt.show()

    # model
    OPTIMIZER = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)
    LOSS_FUNC = mylosses.l1_margin01_dice_loss
    REGU_COEF = 0.001
    ACT_REGU_COEF = None
    OUP_ACT = 'linear'
    USE_RELU_WRAPPER = True

    #--------------------------------------
    model1 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model1 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model1)
        model1.summary()
    print('load weights')

    model_path = os.path.join('result', '19111714_featvec_deeplab_v3_17_10_4', 'deeplav.h5')
    model1.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model2 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model2 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model2)
        model2.summary()
    print('load weights')

    model_path = os.path.join('result', '19111713_featvec_deeplab_v3_17_10_3', 'deeplav.h5')
    model2.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model3 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model3 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model3)
        model3.summary()
    print('load weights')

    model_path = os.path.join('result', '19111712_featvec_deeplab_v3_17_10_3', 'deeplav.h5')
    model3.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model4 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=1/1)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model4 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model4)
        model4.summary()
    print('load weights')
    
    model_path = os.path.join('result', '19111610_featvec_deeplab_v3_10_1', 'deeplav.h5')
    model4.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    model5 = mydeeplab.mydeeplab_featvec_v2(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, 
                                           regu_coef=REGU_COEF, 
                                           oup_act=OUP_ACT, act_regu_coef=ACT_REGU_COEF,
                                           downsize_rate=2/3)
    # load
    if USE_RELU_WRAPPER:
        print('using relu wrapper')
        model5 = mydeeplab.mydeeplab_featvec_wrapper_relu_last(model5)
        model5.summary()
    print('load weights')
    
    model_path = os.path.join('result', '19111601_featvec_deeplab_v3_5_16_1', 'deeplav.h5')
    model5.load_weights(model_path)
    #--------------------------------------
    #--------------------------------------
    N_VEC = 8
    N_LAST_HIDDEN = N_VEC * 2
    model6 = mydeeplab.mydeeplab_featvec_v4(input_shape=(HEIGHT, WIDTH, CHANNELS), num_class=4, n_vec=N_VEC, n_last_hidden=N_LAST_HIDDEN, downsize_rate=2/3)
    model_path = os.path.join('result', '19111207_featvec_deeplab_v5_1', 'deeplav.h5')
    model6.load_weights(model_path)
    #--------------------------------------

    #--------------------------------------
    model_list = [model1, model2, model3, model4, model5, model6]
    #--------------------------------------

    # #####################
    # evaluation
    # #####################

    thresholds_list = [
        [.3, .3, .3, .3],
        ]

    for threshs in thresholds_list:
        # Threshold and mask size tunning
        #  - Here we could use some kind of parameter search, but to simplify I'm using default values
        class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
        best_tresholds = threshs
        best_masks = [25000, 20000, 22500, 15000]

        for index, name in enumerate(class_names):
            print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

        # Model evaluation
        if EVAL_TRA:
            train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Train')
            print(train_metrics)
            train_metrics.to_csv(os.path.join(RESULT_DIR, 'train_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))
        if EVAL_VAL:
            validation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=SEED, preprocessing=preprocessing, set_name='Validation')
            print(validation_metrics)
            validation_metrics.to_csv(os.path.join(RESULT_DIR, 'validation_metrics' + '_' + '-'.join(map(str, best_tresholds)) + '_' + '.csv'))

    class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']
    best_tresholds = [.3, .3, .3, .3]
    best_masks = [25000, 20000, 22500, 15000]

    for index, name in enumerate(class_names):
        print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))

    # #####################
    # test
    # #####################
    if TEST:
        # Apply model to test set
        for i in range(len(model_list)):
            model_list[i] = tta_segmentation(model_list[i], h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean', rotation=180)

        #model = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean', rotation=180)
    
        # test data
        test_imgs, test_imageName_to_imageIdx_dict = read_img((HEIGHT, WIDTH, CHANNELS), test_images_dest_path, test)

        test_df = []
        for i in range(0, test.shape[0], 300):
            print(' {0}'.format(i))
            batch_idx = list(range(i, min(test.shape[0], i + 300)))
            batch_set = test[batch_idx[0]: batch_idx[-1]+1]
        
            test_generator = mygen.DataGenerator2(
                              images=test_imgs,
                              imageName_to_imageIdx_dict=test_imageName_to_imageIdx_dict,
                              masks=None,
                              imageName_to_maskIdx_dict=None,
                              dataframe=batch_set,
                              batch_size=1, 
                              target_size=(HEIGHT, WIDTH),
                              n_channels=CHANNELS,
                              n_classes=N_CLASSES,
                              preprocessing=preprocessing,
                              seed=SEED,
                              mode='predict',
                              shuffle=False)

            for i, md in enumerate(model_list):
                if i == 0:
                    preds = md.predict_generator(test_generator)
                else:
                    preds = preds + md.predict_generator(test_generator)
            preds = preds / len(model_list)

            #preds = model.predict_generator(test_generator)

            for index, b in enumerate(batch_idx):
                filename = test['image'].iloc[b]
                image_df = submission[submission['image'] == filename].copy()
                pred_masks = preds[index, ].round().astype(int)
                pred_rles = build_rles(pred_masks, reshape=(350, 525))
                image_df['EncodedPixels'] = pred_rles

                ### Post procecssing
                pred_masks_post = preds[index, ].astype('float32') 
                for class_index in range(N_CLASSES):
                    pred_mask = pred_masks_post[...,class_index]
                    pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                    pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                    pred_masks_post[...,class_index] = pred_mask
                #pred_masks_post = post_process_in_black(pred_masks_post, test_imgs[test_imageName_to_imageIdx_dict[filename]])

                pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
                image_df['EncodedPixels_post'] = pred_rles_post
                ###
        
                test_df.append(image_df)

        sub_df = pd.concat(test_df)

        # Regular submission
        submission_df = sub_df[['Image_Label' ,'EncodedPixels']]
        submission_df.to_csv(os.path.join(RESULT_DIR, 'submission.csv'), index=False)
        print(submission_df.head())

        # Submission with post processing
        submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]
        submission_df_post.columns = ['Image_Label' ,'EncodedPixels']
        submission_df_post.to_csv(os.path.join(RESULT_DIR, 'submission_post.csv'), index=False)
        print(submission_df_post.head())

    # #####################
    # Inspecting
    # #####################
    if SHOW_IMG:
        # Inspecting some of the validation set predictions
        # ## Without post-processing

        # Choose 3 samples at random
        images_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)
        inspect_set = train[train['image'].isin(images_to_inspect)].copy()
        inspect_set_temp = []

        inspect_generator = DataGenerator(
                            directory=validation_images_dest_path,
                            dataframe=inspect_set,
                            target_df=train,
                            batch_size=1, 
                            target_size=(HEIGHT, WIDTH),
                            n_channels=CHANNELS,
                            n_classes=N_CLASSES,
                            preprocessing=preprocessing,
                            seed=SEED,
                            mode='fit',
                            shuffle=False)

        preds = model.predict_generator(inspect_generator)

        for index, b in enumerate(range(len(preds))):
            filename = inspect_set['image'].iloc[b]
            image_df = inspect_set[inspect_set['image'] == filename].copy()
            pred_masks = preds[index, ].round().astype(int)
            pred_rles = build_rles(pred_masks, reshape=(350, 525))
            image_df['EncodedPixels_pred'] = pred_rles
    
            ### Post procecssing
            pred_masks_post = preds[index, ].astype('float32') 
            for class_index in range(N_CLASSES):
                pred_mask = pred_masks_post[...,class_index]
                pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])
                pred_mask = post_process_closing(pred_mask, kernel_size=20, n_open=0, n_close=1)
                pred_masks_post[...,class_index] = pred_mask
            #pred_masks_post = post_process_in_black(pred_masks_post, valid_imgs[valid_imageName_to_imageIdx_dict[filename]])

            pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))
            image_df['EncodedPixels_pred_post'] = pred_rles_post
            ###
            inspect_set_temp.append(image_df)

        inspect_set = pd.concat(inspect_set_temp)
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')


        # With post-processing
        inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')

        # Inspecting some of the test set predictions
        if TEST:
            # 
            # Without post-process
            # Choose 5 samples at random
            images_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)

            # ## With post-process
            inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')

    return